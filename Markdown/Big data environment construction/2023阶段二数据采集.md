# 2023阶段二数据采集

## 一、[启动环境和基本操作](#initiate)

- ### 1、[Hadoop](#hadoop)

- ### 2、[Zookeeper](zookeeper)

- ### 3、[MySQL](#mysql)

- ### 4、[Flume](#flume)

- ### 5、[Kafka](#kafka)

- ### 6、[Flink](#flink)

- ### 7、[HBase](#hbase)

- ### 8、[Clickhouse](#clickhouse)

- ### 9、[Maxwell](#maxwell)

## 一、<a id="initiate">启动环境和基本操作</a>

### 1、<a id="hadoop">Hadoop</a>

```
/usr/local/src/hadoop/sbin/start-all.sh
```

- #### 1)、检查是否启动成功

  - 在主节点上输入jps

    ```
    namenode
    datanode
    nodemanager
    resourcemanager
    secondarynamendoe
    ```

  - 在其他从机节点上输入jps

    ```
    datanode
    nodemanager
    ```

  - 查看是否可以打开hadoop的webUI管理界面

    ```
    主节点虚拟机IP:9870
    ```

    

- #### 2、运行案例

  ````
  hadoop jar /usr/local/src/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /test/word.txt /out
  ````

  

- ### 3、可能遇到的问题

- 如果需要重置hadoop文件系统重新格式化的话，那么将core-site.xml中配置的那个hadoop.tmp.dir目录给删了，让其重新创建
- 

<br>



### 2、<a id="zookeeper">Zookeeper</a>

```
每台机器上分别启动
/usr/local/src/zookeeper/bin/zkServer.sh  start
```

- ### 查看状态

  ```
  zkServer.sh status
  ```

- ### 查看进程

  ```
  zookeeper启动后的进程：QuorumPeerMain
  ```

  

### 3、<a id="mysql">MySQL</a>

- ### 1、启动

  ```
  service mysql restart
  ```

  

### 4、<a id="flume">Flume</a>

- ### 1、配置采集器的内容

  - 1、**采集文件中**内容变化的数据

    ```
    # 创建并打开文件
    vim file.conf
    
    #定义采集器的三个组件名称
    a1.sources=r1
    a1.channels=c1
    a1.sinks=k1
    
    #数据从哪来（某个机器的端口中来）
    a1.sources.r1.type=exec
    a1.sources.r1.command=tail -F /opt/file/work.txt
    
    #数据缓存到内存中
    a1.channels.c1.type=memory
    
    #数据打印到控制台（到哪去）
    a1.sinks.k1.type=logger
    
    #绑定三者关联
    a1.sources.r1.channels=c1
    a1.sinks.k1.channel=c1
    ```

    - 监听文件（向文件中追加内容）

      ```
      echo "内容">>/opt/file/work.txt
      ```

  - 2、Flume**采集端口**数据后**存入Kafka中**

    ```
    vim duankou.conf
    
    #定义采集器的三个组件名称
    a1.sources=r1
    a1.sinks=k1
    a1.channels=c1
    
    #数据从哪来（某个机器的端口中来）
    a1.sources.r1.type=netcat
    a1.sources.r1.bind=localhost
    a1.sources.r1.port=25001
    
    #数据缓存到内存中
    a1.channels.c1.type=memory
    
    #数据放到kafka中（到哪去）
    a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink
    a1.sinks.k1.brokerList=bigdata1:9092,bigdata2:9092,bigdata3:9092
    a1.sinks.k1.topic=ods_mall_log
    
    #绑定三者关联
    a1.sources.r1.channels=c1
    a1.sinks.k1.channel=c1
    
    ```

    - 监听端口
      - 在其他机器上执行（先启动flume对端口进行监听，然后使用nc连接这个端口发送数据）


    ```
    nc bigdata1 12000
    ```

- ### 2、启动

  ```
  flume-ng agent -c conf -f /usr/local/src/flume/conf/duankou.conf --name a1 -Dflume.root.logger=INFO,console
  								采集创建的文件路径 		文件名		等于: -n 	
  ```

- ### 3、测试

  - 1）测试端口的话：使用其他机器终端，nc 主机名 端口号

    ```
    在 bigdata2上
    nc bigdata1 12000
    ```

  - 2）测试文件的话：  echo "内容">>文件名

- 



### 5、<a id="kafka">Kafka</a>

- ### 1、启动

  ```
  三台机器分别启动kafka（先保证zookeeper是正常的）
  kafka-server-start.sh -daemon /usr/local/src/kafka/config/server.properties
  【说明：-daemon代表后台进程方式启动】
  【kafka启动后进程就是kafka】
  ```

- ### 2、停止kafka服务

  ```
  停止kafka服务
  ```

- #### 3、kafka的使用

  - 1】创建主题

    ```
    kafka-topics.sh --create --zookeeper bigdata1:2181 --replication-factor 1 --partitions 1 --topic 主题名
    ```

  - 2】查看主题

    ```
    kafka-topics.sh --list --zookeeper bigdata1:2181
    ```

  - 3】删除主题

    - 说明：启动Kafaka时如果加载的配置文件中"server.properties"没有配置"delete.topic.enable=true"，那么此时的删除并不是真正的删除，而是把该topic标记为"marked for deletion"。追加参数后记得重启Kafka。

    ```
    kafka-topics.sh --delete --zookeeper bigdata1:2181  --topic 主题名
    ```

  - 4】启动生产者【模拟向kafka的指定主题发送数据】

    ````
    kafka-console-producer.sh --broker-list bigdata1:9092 --topic 主题名
    ````

  - 5】启动消费者【模糊查看kafka指定主题的数据】

    ```
    kafka-console-consumer.sh --bootstrap-server bigdata1:9092 --topic 主题名 --from-beginning
    ```

    

### 6、<a id="flink">Flink</a>

### 7、<a id="hbase">HBase</a>

### 8、<a id="clickhouse">Clickhouse</a>

### 9、<a id="maxwell">Maxwell</a>



