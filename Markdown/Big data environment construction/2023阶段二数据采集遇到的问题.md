# 2023阶段二数据采集遇到的问题

- ## 1、[分区模式](#nonstrict)



## 1、<a id="nonstrict">分区模式</a>

- ### 错误

  ````
  org.apache.spark.SparkException: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict
  ````

- ### 原因

  - 动态分区的模式默认是严格模式

- ### 解决

  ```
  在创建sparksession对象时添加
  .config("hive.exec.dynamic.partition.mode", "nonstrict") // 设置分区的模式是非严格模式
  
  // 在spark-shell中重新执行
  val spark = SparkSession.builder().appName("IncrementalExtraction")
        .enableHiveSupport() // 开启hive支持
        .config("hive.exec.dynamic.partition", "true") // 开启动态分区
        .config("hive.exec.dynamic.partition.mode", "nonstrict") // 设置分区的模式是非严格模式
        .config("hive.exec.max.dynamic.partitions", 2000) // 设置分区的数量
        .config("spark.sql.parser.quotedRegexColumnNames", "true") // 允许在用引号引起来的列名称中使用正则表达式
        .getOrCreate()
  ```

  

  