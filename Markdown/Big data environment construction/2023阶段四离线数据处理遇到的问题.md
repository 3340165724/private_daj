# 2023阶段四离线数据处理遇到的问题

- ## 1、[覆盖数据到dwd层](#OverwriteDwd)

- ## 2、[hbase的任何命令都用不了](#KeeperErrorCode )

- ## 3、[指定分区与现有表分区不匹配](#SpecifiedPartitioning)





## 1、<a id="OverwriteDwd">覆盖数据到dwd层</a>

- ### 错误

  ```
  2023-09-07 21:33:58,710 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
  org.apache.spark.sql.AnalysisException: Cannot overwrite table 2023_dwd1_ds_db01.dim_customer_inf that is also being read from
  ```

- ### 原因

  - 无法边读边写

- ### 解决

  ```
  // 注释这种写入方式
  all_df.write.mode(SaveMode.Overwrite).format("hive").partitionBy("etl_date").saveAsTable(s"2023_dwd1_ds_db01.dim_${table}") 
  
  // 使用insert语句覆盖写入表的时候不存在读写的问题
  all_df.createOrReplaceTempView("mytable")
  spark.sql(s"insert overwrite 2023_dwd1_ds_db01.dim_${table} select `(etl_date)?+.+`,etl_date from mytable")
  // 注意应用正则表达式
   .config("spark.sql.parser.quotedRegexColumnNames", "true") // 允许在用引号引起来的列名称中使用正则表达式
  ```




## 2、<a id="KeeperErrorCode ">hbase的任何命令都用不了</a>

- ### 问题

  ```
  ERROR: KeeperErrorCode = NoNode for /hbase/master
  ```

- ### 原因

  - 1、zookeeper有个节点挂了，查看节点
  - 2、HMaster挂了或者没有启动

- ### 解决

  - 1、查看zookeeper状态
  - 2、那台机器的zookeeper挂了，就重启那台机器（zkServer.sh  start）




## 3、<a id="SpecifiedPartitioning">指定分区与现有表分区不匹配</a>

- ### 问题

  ```
  Specified partitioning does not match that of the existing table dwd.dim_customer_inf.
  Specified partition columns: []
  Existing partition columns: [etl_date]
  ```

- ### 原因

  - 1、分区名写错
  - 2、写入数据时没指定分区

- ### 解决

  ```
  all_df.write.mode(SaveMode.Append).format("hive").partitionBy("etl_date").saveAsTable(s"dwd.${dwd_table}")
  ```

  

  