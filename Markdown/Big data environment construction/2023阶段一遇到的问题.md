## 2023阶段一遇到的问题

### 一、[Hadoop](#hadoop)

### 二、[hive](#hive)

### 三、[Flink](#flink)

### 四、[环境变量](#path)







### 一、<a id="hadoop">Hadoop问题和解决问题</a>

 #### 1、需要重新格式化时

```
1、core-site.xml中配置的那个hadoop.tmp.dir目录给删了
2、删除Hadoop目录下的logs目录
```

#### 2、运行案例时可能出现的错误

- 找不到或无法加载主类

  ```
  问题：
  [2022-12-12 11:40:13.869]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
  Last 4096 bytes of prelaunch.err :
  Last 4096 bytes of stderr :
  错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster
  
  
  解决：
  在命令行输入：hadoop classpath
  把上述输出的值添加到yarn-site.xml文件对应的属性 yarn.application.classpath下面
  <property>
        <name>yarn.application.classpath</name>    	<value>/usr/local/src/hadoop/etc/hadoop:/usr/local/src/hadoop/share/hadoop/common/lib/*:/usr/local/src/hadoop/share/hadoop/common/*:/usr/local/src/hadoop/share/hadoop/hdfs:/usr/local/src/hadoop/share/hadoop/hdfs/lib/*:/usr/local/src/hadoop/share/hadoop/hdfs/*:/usr/local/src/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/src/hadoop/share/hadoop/mapreduce/*:/usr/local/src/hadoop/share/hadoop/yarn:/usr/local/src/hadoop/share/hadoop/yarn/lib/*:/usr/local/src/hadoop/share/hadoop/yarn/*
  </value>
  </property>
  ```

- 进入安全模式

  ```
  问题：
  报错中提示name node is safe mode，则执行命令退出安全模式
  
  解决：
  hdfs dfsadmin -safemode leave
  ```




#### 3、web页面无法进入目录

- 问题（权限不够）

  ```
  Permission denied: user=dr.who, access=READ_EXECUTE, inode="/tmp":root:supergroup:drwx-wx-wx
  ```

- 解决

  ```
  hdfs dfs -chmod -R 777 /
  ```

  

### 二、<a id="hive">hive</a>

- 常见错误1

  ```
  ClassNotFoundException : com.mysql.jdbc.Driver
  
  1》javax.jdo.option.ConnectionDriverName配置错误
  2》java练级mysql的驱动没有放到hive/lib下
  ```

-  常见错误2

  ```
  Access denied for user 'rootaaa'@'bigdata1' (using password: YES)
  
  1》连接mysql的账号或密码写错了
  ```

- 常见错误3

  ```
  CommunicationsException : Communications link failure
  
  1》mysql所在机器的ip地址写错了
  2》mysql不允许通过ip远程连接【授权远程连接】
  ```

-  常见错误4：版本检测错误

  ```
  hive.metastore.schema.verification
                      false
  ```

-  常见错误5

  ```
  如果使用自带模板修改的hive-site.xml，有时会报
  expansion character (code 0x8 at [row,col,system-id]: [3215,96,"file:/usr/local/src/hive/conf/hive-site.xml"]特殊字符的问题，   将3215行的“&#8”给删了即可。
            显示行号  :set number
            定位到行号： :3215
            关闭行号  set nonu
  ```

- 常见错误6（启动）

  ```
  NoSuchMethodError:com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
  
  1》包冲突问题，hive/lib下的guava包和hadoop中的guava冲突【见上面hive的那个冲突包解决】
  ```

- 常见错误7（启动）

  ```
  SafeModeException报hadoop的namenode处于安全模式
  
   1》hdfs dfsadmin -safemode leave
  ```

-  常见错误8（启动）

  ```
  URISyntaxException: Relative path in absolute URI:${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D
  
  1》删除hive-site.xml中下列几个配置：
  hive.querylog.location
  hive.exec.local.scratchdir
  hive.downloaded.resources.dir
  ```



### <a id="flink">Flink</a>

问题：Flink on yarn运行时，没有找到执行程序

```
------------------------------------------------------------
 The program finished with the following exception:

java.lang.IllegalStateException: No Executor found. Please make sure to export the HADOOP_CLASSPATH environment variable or have hadoop in your classpath. For more information refer to the "Deployment" section of the official Apache Flink documenta
```

解决：在运行案例前添加环境

```
export HADOOP_CLASSPATH=`${HADOOP_HOME}/bin/hadoop classpath`
flink run -m yarn-cluster /usr/local/src/flink/examples/batch/WordCount.jar
```





#### <a id="path">环境变量</a>

问题：命令未找到的解决方法

>错误信息
>
>-bash: ls: command not found 

解决：

>运行：export PATH=/bin:/usr/bin:$PATH
>
>查看环境变量：vim /root/.bash_profile

