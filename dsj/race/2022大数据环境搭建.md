## 大数据环境搭建



### 一、[IP配置](#ip)

### 二、[防火墙](#firwalld)

### 三、[修改主机名 / 添加映射 ](#host)

### 四、[ssh](#ssh)

### 五、[搭建MySQL服务](#mysqlService)

### 六、[环境变量](#path)

### 七、[配置Java](#jdk)

### 八、[配置Scala](#scala)

### 九、[配置Hadoop文件](#hadoop)

### 十、[配置hive文件](#hive)

### 十一、[配置zookeeper文件](#zookeeper)

### 十二、[配置Flink文件](#flink)

### 十三、[配置spark](#spark)

### 十四、[配置Kafka文件](#kafka)

### 十五、[配置Flume文件](#flume)



### 一、<a id="ip">IP配置</a>

#### 1、编辑文件ifcfg-ens33

```
vi /etc/sysconfig/network-scripts/ifcfg-ens33

# 修改配置文件
BOOTPROTO=dhcp # 将dhcp（动态的）改为static（静态的）
ONBOOT=no	# 将no改为yes
# 在配置文件最下面添加
IPADDR=92.168.125.128 # IP
NETMASK=255.255.255.0  # 子网掩码
GATEWAY=192.168.125.2  # 网关
DNS1=114.114.114.114   # DNS
# 保存并退出
:wq
```

#### 2、重启网络服务

```
service network restart
```

#### 3、查看IP

```
ip addr
```



### 二、<a id="firwalld">防火墙设置</a>

#### 1、暂时关闭防火墙

```
systemctl stop firewalld
```

#### 2、永久关闭防火墙

```
systemctl disable firewalld
```

#### 3、查看防火墙状态

```
systemctl status firewalld

注意：#提示 Active: inactive (dead)  则关闭成功
```

#### 4、关闭SELINUX

```
# 暂时关闭
setenforce 0

# 永久关闭 （修改配置文件）
vim /etc/selinux/config
SELINUX=enforcing    //将enforcing改为disabled
```



### 三、<a id="host">修改主机名 / 添加映射</a>

#### 1、修改主机名

```
vim /etc/hostname
```

#### 2、添加映射（IP 主机名）

```
vim /etc/hosts

  ip          需改后的主机名
192.168.100.230  master
192.168.100.231  slave1
192.168.100.232  slave2
```

#### 3、重启机器(使修改的主机名生效)

```
reboot
```



### 四、<a id ="SSH">ssh</a>

#### 1、去到家目录

```
cd ~
```

#### 2、生成公钥和私钥（三台机器同时生成公钥）

```
ssh-keygen  -t  rsa
```

#### 3、将公钥拷贝到要免密登录的目标机器上

```
ssh-copy-id  master
ssh-copy-id  slave1
ssh-copy-id  slave2
```



### 五、<a id="mysqlService">搭建MySQL服务 </a>

#### 1、**新建一个文件（ /opt/soft）**

```
mkdir mysql
```

#### 2、进入到该文件夹

```
cd mysql
```

#### 3、安装新版mysql前，需将系统自带的mariadb-lib卸载

```
rpm -qa|grep mariadb
```

#### 4、安装wget

```
yum -y install wget
```

#### 5、远程下载mysql源安装包

```
wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm
```

#### 6、安装mysql源

```
yum localinstall mysql57-community-release-el7-8.noarch.rpm
```

#### 7、检查是否安装成功

```
yum repolist enabled | grep "mysql.*.community.*"

//有六个
```

#### 8、安装MySQL

```
yum install mysql-community-server
```

#### 9、中途有可能会出现 Error: GPG check FAILED问题（这由于源key错误导致的dnf或者yum（软件包管理器）安装软件失败）

```
yum install mysql-community-server --nogpgcheck 
```

#### 10、启动MySQL服务

```
启动：systemctl start mysqld

查看：systemctl status mysqld
```

#### 11、查看初始密码

```
grep "password" /var/log/mysqld.log  //如果找不到初始密码，用下面的试一下
grep 'temporary password' /var/log/mysqld.log
```

#### 12、登录数据库 mysql -uroot -p

```
mysql -uroot -p初始密码
```

#### 13、密码设置的比较简单不符合安全规则（把密码规则改一下，执行下面sql就可以了：）

```
set global validate_password_policy=0;
set global validate_password_length=1;
```

#### 14、修改起始密码

```
set password for 'root'@'localhost'=password('123456');
```

#### 15、设置远程登陆

```
grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;
```

#### 16、**修改** **mysql** **库下的** **user** **表中的** **root** **用户允许任意** **ip** **连接**

```
update mysql.user set host='%' where user='root';
flush privileges;
```

#### 17、退出

```
quit //或者
exit
```



### 六、<a id="path">配置环境变量</a>

#### 1、先获取路径

```
pwd
```

#### 2、复制路径

#### 3、进入到**my_env.sh**文件编辑

```
vim /etc/profile.d/my_env.sh
```

#### 4、在my_env.sh文件中输入

```
#JAVA_HOME
export JAVA_HOME=/usr/local/src/jdk
export PATH=$PATH:$JAVA_HOME/bin

#HADOOP_HOME
export HADOOP_HOME=/usr/local/src/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

#HIVE_HOME
export HIVE_HOME=/usr/local/src/hive
export PATH=$PATH:$HIVE_HOME/bin

#ZOOKEEPER_HOME
export ZOOKEEPER_HOME=/usr/local/src/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin

#KAFKA_HOME
export KAFKA_HOME=/usr/local/src//kafka
export PATH=$PATH:$KAFKA_HOME/bin

# FLINK_HOME
export FLINK=/usr/local/src/flink
export PATH=$PATH:$FLINK_HOME/bin

//保存并退出
：wq
```

#### 6、让修改后的文件生效

```
source /etc/profile.d/my_env.sh
```

#### 7、查看是否配置成功

```
java -version
```



### 七、<a id="jdk">配置Java</a>

#### 1、卸载虚拟机自带的JDK

##### (1）查询是否安装Java软件

```
rpm -qa | grep java
```

##### （2）如果安装的版本低于1.7，卸载该JDK

```
yum -y remove java-1.*
```

#### 2、解压

```
tar -zxvf jdk-8u211-linux-x64.tar.gz -C /usr/local/src/
```

#### 3、重命名（看要求）

#### 4、[配置环境变量](#path)

#### 5、分发到其他集群

```
scp -r /usr/local/src/jdk slave1:/usr/local/src/
scp -r /usr/local/src/jdk slave1:/usr/local/src/
```





### 八、<a id="scala">配置Scala文件</a>





### 九、<a id="hadoop">配置Hadoop文件（/opt/soft/hadoop/hadoop-2.7.7/etc/hadoop）</a>

#### 1、解压

```
tar -zxvf hadoop-2.7.7.tar.gz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv hadoop-2.7.7 hadoop
```

#### 3、[配置环境变量](#path)

#### 4、配置5个文件

#### core-site.xml

``` 
<!-- 指定HDFS中NameNode的地址 -->
<!-- 在java代码中配置hadoop需要调用 -->
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://master:9000</value>
</property>

<!-- 运行Hadoop时产生的临时文件存储的目录 -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/usr/local/src/hadoop/temp</value>
</property>
```

#### hdfs-site.xml

``` 
<!-- 指定namenode的访问地址和端口 -->
<property>
	<name>dfs.namenode.http-address</name>
	<value>master:50070</value>
</property>

<!-- 2nn web访问端口 -->
<property>
	<name>dfs.namenode.secondary.http-address</name>
	<value>slave1:50090</value>
</property>

<!-- 副本个数 -->
<property>
	<name>dfs.replication</name>
	<value>3</value>
</property>
```

#### yarn-site.xml

``` 
<!-- 配置yarn主节点的位置(指定YARN的ResourceManager的地址) -->
<property>
	<name>yarn.resouremanager.hostname</name>
	<value>slave1</value>
</property>

<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>

 <!--关闭虚拟内存验证-->
<property>
	<name>yarn.nodemanager.vmem-check-enabled</name>
	<value>false</value>
</property>

<!--关闭物理内存验证-->
<property>
	<name>yarn.nodemanager.pmem-check-enabled</name>
	<value>false</value>
</property>
```

#### mapred-site.xml（拷贝mapred-site.xml.template）

``` 
<!-- 指定MR运行在YARN上 -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
```

#### slaves / workers（看版本）

````
master
slave1
slave2

注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。
````

### 4、格式化namenode

#### 	1）、进到hadoop目录

```
cd /usr/local/src/hadoop
```

#### 	2）、在格式化

```
hdfs namenode -format
```

#### 	3）、启动集群

```
sbin/start-dfs.sh
sbin/start-yarn.sh
```

#### 	4）、查看进程

```
jps
```





 ### 十、<a id="hive">配置hive文件</a>

#### 1、解压

```
tar -zxvf apache-hive-2.3.4-bin.tar.gz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv apache-hive-2.3.4 hive
```

#### 3、[配置环境变量](#path)

#### 4、解决日志jar包冲突

```
 mv $HIVE_HOME/lib/log4j-slf4j-impl-2.6.2.jar $HIVE_HOME/lib/log4j-slf4j-impl-2.6.2.bak
```

#### 5、拷贝驱动（将 MySQL 的 JDBC 驱动拷贝到 Hive 的 lib 目录下）

```
cp /opt/soft/mysql-connector-java-5.1.34-bin.jar $HIVE_HOME/lib
```

#### 6、 **配置**文件（在$HIVE_HOME/conf目录下复制hive-default.xml.template为hive-site.xml  改五删三）

```
cp hive-default.xml.template  hive-site.xml

# 修改配置文件
vim  hive-site.xml
```

#### 7、改动五处(数据库链接地址,驱动 , 用户名 , 密码,版本效验)

```
 <!-- jdbc 连接的 URL -->
 <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://192.168.66.130:3306/myhive1?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>
  </property>

  <!-- jdbc 连接的 Driver-->
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>

  <!-- jdbc 连接的 username-->
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
    <description>Username to use against metastore database</description>
  </property>

  <!-- jdbc 连接的 password -->
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>123456</value>
  </property>

 <!-- Hive 元数据存储版本的验证 -->
 <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
  </property>
  

# 如果出现错误才改
<property>
    <name>hive.querylog.location</name>
    <value>/opt/data/hive</value>
  </property>
  
  <property>
    <name>hive.exec.local.scratchdir</name>
    <value>/opt/data/hive/tmp</value>
  </property>
  
<property>
    <name>hive.downloaded.resources.dir</name>
    <value>/opt/data/hive/tmp</value>
  </property>
```

#### 8、删除三处（启动hive时报system.io...错误，则删除配置项目：）

```
 <property>
    <name>hive.querylog.location</name>
    <value></value>
    <description>Location of Hive run time structured log file</description>
  </property>

  <property>
    <name>hive.downloaded.resources.dir</name>
    <value></value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>

  <property>
    <name>hive.exec.local.scratchdir</name>
    <value></value>
    <description>Local scratch space for Hive jobs</description>
  </property>
```

#### 9、初始化元数据库

```
schematool -dbType mysql -initSchema

Metastore connection URL:	 jdbc:mysql://192.168.66.131:3306/hiveNo12?createDatabaseIfNotExist=true&characterEncoding=UTF-8&useSSL=false
Metastore Connection Driver :	 com.mysql.jdbc.Driver
Metastore connection User:	 root
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed
```

#### 10、**启动** **Hive**

```
hive
```





### 十一、<a id="zookeeper">配置zookeeper文件</a>

#### 1、解压

```
tar -zxvf zookeeper-3.4.9.tar.gz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv zookeeper-3.4.9 zookeeper
```

#### 3、[配置环境变量](#path)

#### 4、在/usr/local/src/zookeeper目录下创建 zkData

```
cd /usr/local/src/zookeeper

mkdir zkData
```

#### 5、进入到zkData目录，并创建myid文件（**配置服务器编号**）

```
cd /usr/local/src/zookeeper/zkData

vim myid

# 在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格）
1
```

#### 6、配置zoo.cfg文件（重命名/opt/soft/zookeeper/zookeeper-3.4.9/conf下的zoo_sample.cfg 为 zoo.cfg）

```
mv zoo_sample.cfg zoo.cfg
```

####  7、打开 zoo.cfg 文件

```
vim zoo.cfg
 
#修改数据存储路径配置
dataDir=/usr/local/src/zookeeper/zkData

#增加如下配置
#######################cluster##########################
server.1=master:2888:3888
server.2=slave1:2888:3888
server.3=slave2:2888:3888
# 第几号服务器 主机名
```

#### 8、分别启动 Zookeeper

```
bin/zkServer.sh start
```

#### 9、查看状态

```
bin/zkServer.sh status
```



### 十二、<a id="flink">Flink配置</a>

#### 1、解压

```
tar -zxvf flink-1.10.2-bin-scala_2.11.tgz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv flink-1.10.2 flink
```

#### 3、[配置环境变量](#path)

#### 4、修改flink配置文件

- conf/flink-conf.yaml

  ```
  jobmanager.rpc.address: master   //(注意冒号后有空格)
  ```

- slaves

  ```
  master
  slave1
  slave2
  ```

#### 5、分发

```
scp -r /usr/local/src/flink slave1:/usr/local/src/
scp -r /usr/local/src/flink slave2:/usr/local/src/
```

#### 6、启动flink集群

```
start-cluster.sh
```

#### 7、查看jps进程(注意,因端口冲突,启动flink之前需要先停止spark的相关进程)

```
#slave1
7334 Jps
7687 TaskManagerRunner


#slave2
7334 Jps
7687 TaskManagerRunner


#master
3553 StandaloneSessionClusterEntrypoint
3917 TaskManagerRunner
3999 Jps

```

#### 8、WebUI界面访问查看

```
ip:8081
```

#### 9、运行案例

- 启动flink

  - 1、批处理离线文件 （flink/examples/batch/WordCount.jar）

    ```
    flink run WordCount.jar
    ```

  - 2、流失处理 （flink/examples/streaming/SocketWindowWodCount.jar）

    - 先监听端口nc -l -p xxx

    - flink run sockeWindoWoreCount.jar --hostname master(可变) --port （跟监听端口对应）

    ```
    新打开一个master终端：nc -l 12600
    $ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --hostname master --port 12600
    ```

- 不启动flink，使用yarn方式运行，加入参数： -m yarn-cluster即可

  - 1、批处理离线文件 （flink/examples/batch/WordCount.jar）

    ```
    需要配置：export HADOOP_CLASSPATH=`${HADOOP_HOME}/bin/hadoop classpath`
    flink run -m yarn-cluster /usr/local/src/flink/examples/batch/WordCount.jar
    ```

  - 流失处理 （flink/examples/streaming/SocketWindowWodCount.jar）

    - 1、先监听端口nc -l -p xxx

    - 2、flink run -m  yarn-cluster sockeWindoWoreCount.jar  --hostname master(可变) --port （跟监听端口对应）

      ```
      新打开一个master终端：nc -l 12600
      需要配置：export HADOOP_CLASSPATH=`${HADOOP_HOME}/bin/hadoop classpath`
      flink run -m  yarn-cluster sockeWindoWoreCount.jar  --hostname master(可变) --port （跟监听端口对应）
      ```
      
    - ![flink](C:\Users\Lenov\Pictures\MarkDown\flink.png)



### 十三、<a id="spark">配置spark文件</a>

#### 1、解压

```
tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv spark-2.1.1 spark
```

#### 3、[配置环境变量](#path)

#### 4、配置文件

- 复制spark-env.sh.template 为spark-env.sh

  ```
  cp spark-env.sh.template  spark-env.sh
  
  # 配置文件中可以找到
  export JAVA_HOME=/usr/local/src/jdk
  export HADOOP_CONF_DIR=/usr/local/src/hadoop/etc/hadoop
  
  export SPARK_MASTER_HOST=master
  export SPARK_MASTER_PORT=7077
  
  export SPARK_CONF_DIR=/usr/local/src/spark/conf
  ```

- 复制slaves.template 为 slaves 

  ```
  cp slaves.template slaves
  
  master
  slave1
  slave2
  ```

#### 5、分发

```
scp -r /usr/local/src/spark slave1:/usr/local/src/
scp -r /usr/local/src/spark slave2:/usr/local/src/
```

#### 6、启动集群

```
sbin/start-all.sh
```

#### 7、查看进程

```
#master
3075 Jps
3012 Worker
2917 Master



#slave1
7334 Jps
7256 Worker



#slave2
7334 Jps
7351 Worker

```

#### 8、运行自带的Pi案例

- Spark集群方式运行

  ```
  spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 1g --total-executor-cores 1 /usr/local/src/spark/examples/jars/spark-examples_2.11-2.1.1.jar 100
  ```

- spark-on-yarn方式运行（spark集群无需启动，hadoop需要启动的）

  - 如果使用spark-on-yarn运行时，需要在hadoop的yarn-site.xml中加入关闭内存检测配置，否则报错

    ```
    <property>
                     <name>yarn.nodemanager.pmem-check-enabled</name>
                     <value>false</value>
             </property>
             <property>
                     <name>yarn.nodemanager.vmem-check-enabled</name>
                     <value>false</value>
             </property>
    ```

  ```
  spark-submit --class org.apache.spark.examples.SparkPi --master yarn --executor-memory 1g --total-executor-cores 1 /usr/local/src/spark/examples/jars/spark-examples_2.11-2.1.1.jar 100
  ```







### 十四、<a id="kafka">Kafka配置</a>

#### 1、解压

```
tar -zxvf kafka_2.11-2.0.0.tgz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv kafka_2.11-2.0.0  kafka
```

#### 3、[配置环境变量](#path)

#### 4、修改配置文件（kafka/config/server.properties）（改4增1）

```
broker.id=1  (集群中其他broker.id为2、3)

# 推荐使用具体IP跟上端口号
host.name=XXX.XXX.XXX.XXX （主节点IP）
listeners=PLAINTEXT://XXX.XXX.XXX.XXX:9092  （主节点IP）
log.dirs=/usr/local/src/kafka/logs                                                                       
zookeeper.connect=XXX.XXX.XXX.XXX:2181,XXX.XXX.XXX.XXX:2181,XXX.XXX.XXX.XXX:2181
```

#### 5、将kafka拷贝到其他机器上

```
scp -r /usr/local/src/kafka slave1:/usr/local/src
 scp -r /usr/local/src/kafka slave2:/usr/local/src
```

#### 6、分别启动集群

```
kafka-server-start.sh -daemon /usr/local/src/kafka/config/server.properties
										配置文件所在路径
```

#### 7、创建主题（随便在哪个节点都行）

````
kafka-topics.sh --create --zookeeper master:2181 --replication-factor 1 --partitions 1 --topic lol
																							  主题名称
````

#### 8、查看主题

```
kafka-topics.sh --zookeeper slave1:2181 --list
```

#### 9、启动生产者（向主题下发送数据：）(flume充当生产者)

```
 kafka-console-producer.sh --broker-list master:9092 --topic lol
```

#### 1、启动消费者（查看kafka中主题的数据）（Flink充当消费者）

```
kafka-console-consumer.sh --bootstrap-server master:9092 --topic lol --from-beginning
															主题名
```

#### 11、删除主题：

```
kafka-topics.sh --zookeeper master:2181 --delete --topic lol
```



### 十五、<a id="flume">Flume配置</a>

#### 1、解压

```
tar -zxvfapache-flume-1.7.0-bin.tar.gz /usr/local/src/
```

#### 2、重命名（看要求）

```
mv apache-flume-1.7.0 flume
```

#### 3、[配置环境变量](#path)

#### 4、查看flume环境变量是否生效

```
flu + tab键 =====》 flume -ng 
```

#### 5、创建并编辑文件

```
vim duankou.conf
```

- 1、监听端口

  ```
  #采集器命名
  a1.sources=r1
  a1.channels=c1
  a1.sinks=k1
  
  #数据来源(来自于端口)
  # netcat：网络端口来收集，master：绑定的主机，26001：主机的那个端口
  # 注意：获取不到数据八master换成localhost再不行换成ip还不行换成 172.0.0.1
  a1.sources.r1.type=netcat  
  a1.sources.r1.bind=master
  a1.sources.r1.port=26001
  #数据缓存描述(缓存到内存)
  a1.channels.c1.type=memory
  #数据输出到控制台
  a1.sinks.k1.type=logger
  
  #关联组件
  a1.sources.r1.channels=c1
  a1.sinks.k1.channel=c1
  ```

- 2、监听文件变化,输出到控制台

  ````
  #采集器组件起名字
  a1.sources=r1
  a1.channels=c1
  a1.sinks=k1
  
  #数据来源描述(来自于文件)
  a1.sources.r1.type=exec
  a1.sources.r1.command=tail -F /opt/flume.txt
  
  #数据缓存描述(缓存到内存)
  a1.channels.c1.type=memory
  
  #描述数据sink到哪(logger --> 输出到控制台)
  a1.sinks.k1.type=logger
  
  #关联组件
  a1.sources.r1.channels=c1
  a1.sinks.k1.channel=c1
  ````

- 3、监听端口,sink到Kafka

  ```
  a1.sources=r1
  a1.channels=c1
  a1.sinks=k1
  
  a1.sources.r1.type=netcat
  a1.sources.r1.bind=master
  a1.sources.r1.port=26001
  
  a1.channels.c1.type=memory
  
  a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink
  a1.sinks.k1.kafka.bootstrap.servers=master:9092,slave1:9092,slave2:9092
  a1.sinks.k1.kafka.topic=flumeTest
  
  a1.sources.r1.channels=c1
  a1.sinks.k1.channel=c1
  ```

#### 6、启动flume集群

```
flume-ng agent -c conf -f /usr/local/src/flume/conf/文件名.conf --name a1 -Dflume.root.logger=INFO,console
								上面创建的文件路径
```

#### 7、测试

- 1）测试端口的话：使用其他机器终端，nc 主机名 端口号

  ```
  在 slave1上
  nc master 26001
  ```

- 2）测试文件的话：  echo "内容">>文件名

#### 8、了解

- 同时将采集的数据放入kafka和hdfs中 (sink到什么地方)
- https://blog.csdn.net/qq_39604679/article/details/123669831





